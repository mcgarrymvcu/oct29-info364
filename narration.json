{
  "01": "A data warehouse’s logical database design is the blueprint that organizes how information will be structured and accessed before any physical implementation. It focuses on defining fact tables, dimension tables, relationships, and hierarchies that support analytical queries. Unlike operational databases, the logical design emphasizes integration, consistency, and ease of reporting across large volumes of historical data. In this lecture, we’ll examine how to translate business requirements into a logical model that balances performance, scalability, and clarity",
  "02": "A data warehouse provides a single, trusted source of truth by consolidating information from multiple systems into one centralized repository. This enables faster, more accurate decision-making since managers and analysts can work with consistent, historical data instead of scattered reports. It also supports trend analysis and forecasting, giving organizations a competitive edge by identifying opportunities and risks earlier. Ultimately, a data warehouse improves efficiency, reduces duplication, and enhances the strategic use of data across the business.",
  "03": "Transactional databases are built for speed on individual records \u2014 things like processing a sale or updating a customer\u2019s address. Analytical systems, on the other hand, are built to answer big-picture questions, like sales trends over time or inventory levels by region. The problem is that if you try to run analytics on a transactional system, it slows down daily operations. That\u2019s why organizations separate the two: OLTP for operations, OLAP for decision-making.",
  "04": "OLTP (Online Transaction Processing) systems are designed for handling day-to-day business operations like order entry, payments, or customer updates—optimized for fast inserts, updates, and queries on small amounts of data. OLAP (Online Analytical Processing), on the other hand, is built for analyzing large volumes of historical data, enabling complex queries, aggregations, and trend analysis across multiple dimensions. In short, OLTP powers real-time transactions, while OLAP supports strategic decision-making through data analysis and reporting.",
  "05": "When we talk about deploying a data warehouse, we’re really talking about a structured, step-by-step methodology. It begins with defining business requirements so we’re clear on what questions the warehouse should answer. From there, we move into data modeling and ETL—extracting, transforming, and loading data from multiple sources into a consistent structure. The next steps involve building the warehouse itself, testing for data quality, and then deploying tools like OLAP or dashboards for analysis. The overall goal is to deliver a reliable system that turns raw data into useful insights for decision-making.",
  "06": "This slide shows a slightly different perspective on how to build a data warehouse, starting with identifying the key business entities—like products, regions, or time periods—and the measures we want to analyze, such as revenue or sales. Next, we determine the grain of the fact tables, meaning the level of detail for each record, which drives both the accuracy and the size of the data. From there, we design a star schema to connect facts and dimensions, making sure aggregations across dimensions don’t create errors with things like averages or ratios. Finally, we tie the design back to actual data sources, define the ETL processes, and load the data so it’s ready for reporting and analysis.",
  "07": "A fact table holds the measurable, numeric data that represents business events, like sales amounts, quantities ordered, or revenue. You can think of it as the scoreboard that captures what happened. A dimension table provides the descriptive context that explains those facts, such as product names, customer details, time periods, or store locations. When you put them together, the fact table tells you the numbers, and the dimension tables let you slice and analyze those numbers by different perspectives, like sales by product or revenue by region.",
  "08": "A star schema is a way of organizing data in a warehouse where a central fact table is linked to multiple dimension tables. The fact table holds the numbers we want to analyze, while the dimension tables provide descriptive details that give those numbers meaning. It’s called a star schema because the diagram looks like a star, with the fact table in the center and dimensions radiating outward. This design is widely used in data warehousing because it’s simple, easy to understand, and makes queries run faster by minimizing the number of joins and making aggregations more efficient, which is especially important for large analytical workloads.",
  "09": "",
  "10": "",
  "11": "",
  "12": "",
  "13": "",
  "14": "",
  "15": "Grain is one of the most important decisions you\u2019ll make in a warehouse. It defines the smallest level of detail captured in the fact table. If you go fine-grained, like recording each item in each order, you gain flexibility but require more storage. If you go coarse-grained, like daily totals, it\u2019s faster but limits what kinds of questions you can answer later.",
  "16": "Summarizability problems happen when your dimensions don\u2019t align properly with your facts. If rollups or drill-downs don\u2019t work, you\u2019ll get misleading totals or gaps in analysis. This usually happens with incomplete or non-strict hierarchies in your dimension tables. Getting summarizability right is crucial for trustworthy reporting.",
  "17": "Here\u2019s an example: if your product hierarchy is missing some categories, then rolling up sales by department might leave some items uncounted. Or if relationships aren\u2019t strictly one-to-many, your aggregations may double-count. These errors undermine trust in the warehouse. It\u2019s why data modeling discipline is so important.",
  "18": "To fix summarizability problems, you have several tools. You can add missing records or default values for incomplete hierarchies. You can adjust the ETL process to ensure relationships are correct when data is loaded. And for many-to-many relationships, you might introduce bridge tables or alternative hierarchies.",
  "19": "Let\u2019s look at a financial data mart. The fact table might store transactions like revenue and expenses. Dimensions might include time, account, or department. From this, you can generate reports like quarterly income statements or department-level expense summaries.",
  "20": "Here\u2019s a design exercise: take a set of operational tables and convert them into a star schema. The fact table will capture orders and order lines. Dimensions like product, shop, and customer give context. This practice helps solidify how to move from theory to an actual design.",
  "21": "And here\u2019s the solution: the fact table has the sales events, while the dimensions give descriptive power. Product, shop, and customer all link to the facts. This simple schema allows powerful queries with minimal joins. It\u2019s a practical illustration of dimensional modeling at work.",
  "22": "Consider another case: employee data. Suppose management wants to analyze salaries across departments, by tenure, or by location. You\u2019d design a star schema with employee facts and dimensions like department, job title, or office. This exercise shows how flexible the star schema approach can be.",
  "23": "One more design challenge: what is the subject area for this data mart? This pushes you to think about the boundaries of analysis. Are you focusing on sales, inventory, HR, or something else? Clear subject definition is the first step to a good warehouse.",
  "24": "Dimension values don\u2019t always stay the same, and that\u2019s where slowly changing dimensions come in. There are three main approaches. Type 1 simply overwrites values, losing history. Type 2 creates a new record to preserve history, and Type 3 adds a separate column to track old and new values.",
  "25": "Here\u2019s an example of Type 2: a customer\u2019s tax bracket changes from medium to high. Instead of overwriting, you add a new row with effective dates. That way, queries run against historical periods still reflect the old value, while new queries use the updated value. This preserves accuracy over time.",
  "25": "Here\u2019s an example of Type 3: again, the customer\u2019s tax bracket changes from medium to high. In this case, you add columns for current and previous bracket. You don\u2019t preserve the full history, but you keep a snapshot of the change. This is simpler, but less detailed than Type 2.",
  "27": "Snowflake schemas are a variation on star schemas. They normalize the dimension tables to save space and handle large, dynamic data better. The tradeoff is that queries require more joins, so performance can drop. Snowflake is useful in certain scenarios, but the star schema remains the default choice.",
  "28": "To wrap up: you\u2019ll do a data warehousing design exercise to practice what we covered. Next, we\u2019ll move into ETL \u2014 the process of extracting, transforming, and loading data into the warehouse. This is where the design comes to life. ETL is what makes the warehouse usable day-to-day."
}
